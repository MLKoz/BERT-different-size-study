{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets==2.1.0\n!wandb disabled\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import TrainingArguments\nfrom transformers import Trainer\nimport torch\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom datasets import load_dataset\nfrom sklearn.model_selection import train_test_split\nfrom datasets import Dataset\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-28T21:56:14.419069Z","iopub.execute_input":"2022-08-28T21:56:14.419333Z","iopub.status.idle":"2022-08-28T21:56:24.680054Z","shell.execute_reply.started":"2022-08-28T21:56:14.419303Z","shell.execute_reply":"2022-08-28T21:56:24.679091Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"def compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    f1 = f1_score(labels, preds, average=\"weighted\")\n    acc = accuracy_score(labels, preds)\n    precision= precision_score(labels, preds, average=\"weighted\")\n    recall=recall_score(labels, preds, average=\"weighted\")\n    return {\"accuracy\": acc, \"f1\": f1, \"precision\" : precision, \"recall\" : recall}","metadata":{"execution":{"iopub.status.busy":"2022-08-28T21:55:24.134230Z","iopub.execute_input":"2022-08-28T21:55:24.134517Z","iopub.status.idle":"2022-08-28T21:55:24.140124Z","shell.execute_reply.started":"2022-08-28T21:55:24.134485Z","shell.execute_reply":"2022-08-28T21:55:24.139248Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def build_train_and_test(model_complexity, num_labels, seq_max_length, epochs, train_ds, val_ds, test_ds):\n    # zbiory musza byc typu dataset, label i text\n    if model_complexity==\"small\":\n        bert_model_version=\"prajjwal1/bert-tiny\"\n    elif model_complexity==\"normal\":\n        bert_model_version=\"bert-base-uncased\"\n    elif model_complexity==\"large\":\n        bert_model_version=\"bert-large-uncased\"\n    else:\n        print(\"ERROR\")\n        return\n    \n    tokenizer = AutoTokenizer.from_pretrained(bert_model_version)\n    def tokenize(batch):\n        return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=seq_max_length)\n    train_ds_encoded =  train_ds.map(tokenize, batched=True, batch_size=None)\n    test_ds_encoded =  test_ds.map(tokenize, batched=True, batch_size=None)\n    val_ds_encoded =  val_ds.map(tokenize, batched=True, batch_size=None)\n    train_ds_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    test_ds_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    val_ds_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = (AutoModelForSequenceClassification.from_pretrained(bert_model_version, num_labels=num_labels).to(device))\n\n    batch_size=64\n    logging_steps = 1\n    model_name = \"The Warsaw Institute of Technology - EITI - NLP Project\"\n    training_args = TrainingArguments(output_dir=model_name,\n                                     num_train_epochs=epochs,\n                                     learning_rate=2e-5,\n                                     per_device_train_batch_size=batch_size,\n                                     per_device_eval_batch_size=batch_size,\n                                     weight_decay=0.01,\n                                     evaluation_strategy=\"epoch\",\n                                     disable_tqdm=False,\n                                     logging_steps=logging_steps,\n                                     log_level=\"error\")\n    \n    trainer = Trainer(model=model, args=training_args,\n                     compute_metrics = compute_metrics,\n                     train_dataset = train_ds_encoded,\n                     eval_dataset = val_ds_encoded,\n                     tokenizer=tokenizer)\n    trainer.train()\n    preds_output = trainer.predict(test_ds_encoded)\n    return trainer, preds_output.metrics","metadata":{"execution":{"iopub.status.busy":"2022-08-28T21:55:21.674577Z","iopub.execute_input":"2022-08-28T21:55:21.675016Z","iopub.status.idle":"2022-08-28T21:55:21.685429Z","shell.execute_reply.started":"2022-08-28T21:55:21.674983Z","shell.execute_reply":"2022-08-28T21:55:21.684635Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#emotions\ndef load_emotions_dataset():\n    before_train_ds = load_dataset(\"text\", data_files=\"../input/emotions-dataset-for-nlp/train.txt\")['train']\n    before_test_ds = load_dataset(\"text\", data_files=\"../input/emotions-dataset-for-nlp/test.txt\")['train']\n    before_val_ds = load_dataset(\"text\", data_files=\"../input/emotions-dataset-for-nlp/val.txt\")['train']\n    emotion_dict = {'surprise':0, 'love':1 , 'joy':2 , 'fear': 3, 'sadness': 4, 'anger':5}\n    def split_data(data):\n        after_process = data['text'].split(';')\n        data['text'] = after_process[0]\n        data['label'] = emotion_dict[after_process[1]]\n        return data\n    train_ds =  before_train_ds.map(lambda x: split_data(x))\n    test_ds = before_test_ds.map(lambda x: split_data(x))\n    val_ds = before_val_ds.map(lambda x: split_data(x))\n    return train_ds, val_ds, test_ds","metadata":{"execution":{"iopub.status.busy":"2022-08-28T21:55:17.377064Z","iopub.execute_input":"2022-08-28T21:55:17.377328Z","iopub.status.idle":"2022-08-28T21:55:17.384139Z","shell.execute_reply.started":"2022-08-28T21:55:17.377298Z","shell.execute_reply":"2022-08-28T21:55:17.383454Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"#sms\ndef load_sms_dataset():\n    df=pd.read_csv(\"../input/sms-spam-collection-dataset/spam.csv\",encoding='ISO-8859-1')\n    df=df[['v1','v2']]\n    df.rename(columns={'v1':'label','v2':'text'},inplace=True)\n    lab={'spam':0,'ham':1}\n    df['label']=df['label'].replace(lab)\n    train_ds,test_ds=train_test_split(df,test_size=.4,random_state=303)\n    val_ds,test_ds=train_test_split(test_ds,test_size=.5,random_state=303)\n    train_ds=Dataset.from_pandas(train_ds)\n    val_ds=Dataset.from_pandas(val_ds)\n    test_ds=Dataset.from_pandas(test_ds)\n    train_ds=train_ds.remove_columns(\"__index_level_0__\")\n    val_ds=val_ds.remove_columns(\"__index_level_0__\")\n    test_ds=test_ds.remove_columns(\"__index_level_0__\")\n    return train_ds, val_ds, test_ds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#bbc\ndef load_bbc_dataset():\n    testq1 = load_dataset('csv', data_files='../input/newsgroup20bbcnews/bbc-text.csv')\n    x=testq1['train']\n    x.set_format(type='pandas')\n    dftest=x[:]\n    dftest.columns=['label','text']\n    columnsTitles = ['text', 'label']\n    dftest = dftest.reindex(columns=columnsTitles)\n    dftest['label'] = dftest.label.map({'sport':0,'business':1,'tech':2,'entertainment':3,'politics':4})\n    df=dftest\n    train_ds, test_ds = train_test_split(df, test_size=0.4, random_state=303)\n    val_ds, test_ds = train_test_split(df, test_size=0.5, random_state=303)\n    train_ds.columns=['text','label']\n    val_ds.columns=['text','label']\n    test_ds.columns=['text','label']\n    train_ds=Dataset.from_pandas(train_ds)\n    val_ds=Dataset.from_pandas(val_ds)\n    test_ds=Dataset.from_pandas(test_ds)\n    train_ds=train_ds.remove_columns(\"__index_level_0__\")\n    val_ds=val_ds.remove_columns(\"__index_level_0__\")\n    test_ds=test_ds.remove_columns(\"__index_level_0__\")\n    return train_ds, val_ds, test_ds","metadata":{"execution":{"iopub.status.busy":"2022-08-28T21:55:13.825495Z","iopub.execute_input":"2022-08-28T21:55:13.826227Z","iopub.status.idle":"2022-08-28T21:55:13.837298Z","shell.execute_reply.started":"2022-08-28T21:55:13.826168Z","shell.execute_reply":"2022-08-28T21:55:13.836441Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"#imdb\ndef load_imdb_dataset():\n    train_ds = load_dataset(\"imdb\")['train']\n    test_ds = load_dataset(\"imdb\")['test']\n    test_ds.set_format(type=\"pandas\")\n    df = test_ds[:] \n    val_ds, test_ds = train_test_split(df, test_size=0.5, random_state=303)\n    val_ds.columns=['text','label']\n    test_ds.columns=['text','label']\n    val_ds=Dataset.from_pandas(val_ds)\n    test_ds=Dataset.from_pandas(test_ds)\n    val_ds=val_ds.remove_columns(\"__index_level_0__\")\n    test_ds=test_ds.remove_columns(\"__index_level_0__\")\n    return train_ds, val_ds, test_ds","metadata":{"execution":{"iopub.status.busy":"2022-08-28T21:55:12.040774Z","iopub.execute_input":"2022-08-28T21:55:12.042586Z","iopub.status.idle":"2022-08-28T21:55:12.049109Z","shell.execute_reply.started":"2022-08-28T21:55:12.042533Z","shell.execute_reply":"2022-08-28T21:55:12.048288Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"#disaster tweets \ndef load_tweets_dataset():\n    train_data = load_dataset('csv', data_files='/kaggle/input/nlpgettingstarted/train.csv')['train']\n    test_data = load_dataset('csv', data_files='/kaggle/input/nlpgettingstarted/test.csv')['train']\n\n    train_data = train_data.remove_columns(\"location\")\n    train_data = train_data.remove_columns(\"keyword\")\n    train_data = train_data.remove_columns(\"id\")\n\n    #test_data = test_data.remove_columns(\"location\")\n    #test_data = test_data.remove_columns(\"keyword\")\n    #test_data = test_data.remove_columns(\"id\")\n    train_data=train_data.rename_column(\"target\", \"label\")\n    #test_data=test_data.rename_column(\"target\", \"label\")\n    train_data.set_format(type=\"pandas\")\n    df = train_data[:]\n    train_ds, test_ds = train_test_split(df, test_size=0.4, random_state=303)\n    val_ds, test_ds = train_test_split(test_ds, test_size=0.5, random_state=303)\n    train_ds.columns=['text','label']\n    val_ds.columns=['text','label']\n    test_ds.columns=['text','label']\n\n    train_ds=Dataset.from_pandas(train_ds)\n    val_ds=Dataset.from_pandas(val_ds)\n    test_ds=Dataset.from_pandas(test_ds)\n\n    train_ds=train_ds.remove_columns(\"__index_level_0__\")\n    val_ds=val_ds.remove_columns(\"__index_level_0__\")\n    test_ds=test_ds.remove_columns(\"__index_level_0__\")\n    return train_ds, val_ds, test_ds","metadata":{"execution":{"iopub.status.busy":"2022-08-28T21:55:10.045141Z","iopub.execute_input":"2022-08-28T21:55:10.045477Z","iopub.status.idle":"2022-08-28T21:55:10.054477Z","shell.execute_reply.started":"2022-08-28T21:55:10.045443Z","shell.execute_reply":"2022-08-28T21:55:10.052373Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def load_under_study_dataset(ds_name):\n    if ds_name == \"emotions\":\n        return load_emotions_dataset()\n    elif ds_name == \"sms\":\n        return load_sms_dataset()\n    elif ds_name == \"bbc\":\n        return load_bbc_dataset()\n    elif ds_name == \"tweets\":\n        return load_tweets_dataset()\n    elif ds_name == 'imdb':\n        return load_imdb_dataset()","metadata":{"execution":{"iopub.status.busy":"2022-08-28T21:56:51.569281Z","iopub.execute_input":"2022-08-28T21:56:51.569641Z","iopub.status.idle":"2022-08-28T21:56:51.580110Z","shell.execute_reply.started":"2022-08-28T21:56:51.569605Z","shell.execute_reply":"2022-08-28T21:56:51.579379Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"dataset_name = \"emotions\"\ntrain_ds, val_ds, test_ds = load_under_study_dataset(dataset_name)\nnum_labels = len(set(train_ds['label']))\nbert_version = \"small\"\nepochs = 20\nseq_max_length = 50\n\ntrainer, metrics = build_train_and_test(model_complexity = bert_version, num_labels = num_labels, \\\n    seq_max_length = seq_max_length, epochs = epochs,  train_ds = train_ds, val_ds = val_ds, test_ds = test_ds)\nprint(metrics)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T21:56:52.987569Z","iopub.execute_input":"2022-08-28T21:56:52.988359Z","iopub.status.idle":"2022-08-28T22:00:33.845923Z","shell.execute_reply.started":"2022-08-28T21:56:52.988313Z","shell.execute_reply":"2022-08-28T22:00:33.845075Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"dataset_name = \"emotions\"\ntrain_ds, val_ds, test_ds = load_under_study_dataset(dataset_name)\nnum_labels = len(set(train_ds['label']))\nbert_version = \"large\"\nepochs = 2\nseq_max_length = 50\n\ntrainer, metrics = build_train_and_test(model_complexity = bert_version, num_labels = num_labels, \\\n    seq_max_length = seq_max_length, epochs = epochs,  train_ds = train_ds, val_ds = val_ds, test_ds = test_ds)\nprint(metrics)","metadata":{"execution":{"iopub.status.busy":"2022-08-28T22:02:27.268089Z","iopub.execute_input":"2022-08-28T22:02:27.268366Z","iopub.status.idle":"2022-08-28T22:12:40.110165Z","shell.execute_reply.started":"2022-08-28T22:02:27.268337Z","shell.execute_reply":"2022-08-28T22:12:40.108422Z"},"trusted":true},"execution_count":29,"outputs":[]}]}